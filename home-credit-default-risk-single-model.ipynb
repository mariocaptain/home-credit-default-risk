{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4","authorship_tag":"ABX9TyN7P6lJwwaYk/7XvVGvW5oO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# PREDICTING THE PROBABILITY OF DEFAULTING ON A LOAN"],"metadata":{"id":"pmsjAnus4IRu"}},{"cell_type":"markdown","source":["# I. OVERVIEW"],"metadata":{"id":"448BhMX24SGe"}},{"cell_type":"markdown","source":["## 1. DATA\n","The dataset includes various types of information such as demographic data, loan application history, payment records, and credit bureau data.\n","\n","**application_train.csv/application_test.csv**: Contains the main training and test data, including demographic and financial information for each applicant.\n","\n","**bureau.csv**: Contains data about the applicant's previous credits from other financial institutions.\n","\n","**bureau_balance.csv**: Monthly balance of previous credits from the credit bureau.\n","\n","**previous_application.csv**: Previous applications for loans at Home Credit.\n","\n","**POS_CASH_balance.csv**: Monthly balance snapshots of previous point-of-sale and cash loans.\n","\n","**credit_card_balance.csv**: Monthly balance snapshots of previous credit cards.\n","\n","**installments_payments.csv**: Payments made on previous loans."],"metadata":{"id":"HohH_HBd4SNe"}},{"cell_type":"markdown","source":["# II. DATA OVERVIEW AND ANALYSIS"],"metadata":{"id":"0CQAqEgu5r1_"}},{"cell_type":"markdown","source":["## 1. DATA OVERVIEW"],"metadata":{"id":"r5tBrN2O54IW"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywgz7_0y4OTN","executionInfo":{"status":"ok","timestamp":1718155018202,"user_tz":-420,"elapsed":28305,"user":{"displayName":"Nguyen Duc Quoc Anh","userId":"05926175353841331871"}},"outputId":"b0783832-fd9f-42a3-e62f-cd9d49199eb8"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n","\n","# Load main datasets\n","train = pd.read_csv('/content/drive/MyDrive/AI/home-credit-default-risk/data/application_train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/AI/home-credit-default-risk/data/application_test.csv')\n","\n","# Load related datasets\n","bureau = pd.read_csv('/content/drive/MyDrive/AI/home-credit-default-risk/data/bureau.csv')\n","bureau_balance = pd.read_csv('/content/drive/MyDrive/AI/home-credit-default-risk/data/bureau_balance.csv')\n","previous_application = pd.read_csv('/content/drive/MyDrive/AI/home-credit-default-risk/data/previous_application.csv')\n","pos_cash_balance = pd.read_csv('/content/drive/MyDrive/AI/home-credit-default-risk/data/POS_CASH_balance.csv')\n","installments_payments = pd.read_csv('/content/drive/MyDrive/AI/home-credit-default-risk/data/installments_payments.csv')\n","credit_card_balance = pd.read_csv('/content/drive/MyDrive/AI/home-credit-default-risk/data/credit_card_balance.csv')\n","train.shape, test.shape, bureau.shape, bureau_balance.shape, previous_application.shape, pos_cash_balance.shape, installments_payments.shape, credit_card_balance.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6JUr3eop57Xm","executionInfo":{"status":"ok","timestamp":1718155079168,"user_tz":-420,"elapsed":60968,"user":{"displayName":"Nguyen Duc Quoc Anh","userId":"05926175353841331871"}},"outputId":"e7f719b1-b8c5-4c4b-dcd2-33f7e4e47860"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((307511, 122),\n"," (48744, 121),\n"," (1716428, 17),\n"," (27299925, 3),\n"," (1670214, 37),\n"," (10001358, 8),\n"," (13605401, 8),\n"," (3840312, 23))"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["## 2. MERGING DATASETS & FEATURE ENGINEERING\n","In this notebook, we will employ a single-model approach, using only one base model for this problem, namely the LightGBM (Light Gradient Boosting Machine) model.\n","\n","To fit the data to the base model, we will aggregate and merge all the data available in the other datasets into the train and test datasets."],"metadata":{"id":"DsY6dKbYT-1E"}},{"cell_type":"markdown","source":["### 2.1 AGGREGATION FUNCTIONS"],"metadata":{"id":"4xnfWtssCVGM"}},{"cell_type":"code","source":["import lightgbm as lgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_auc_score\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n","\n","def encode_categorical(df):\n","    le = LabelEncoder()\n","    for col in df.columns:\n","        if df[col].dtype == 'object':\n","            df[col] = le.fit_transform(df[col].astype(str))\n","    return df\n","\n","def aggregate_bureau(bureau, bureau_balance):\n","    # Encode STATUS\n","    status_mapping = {'C': 0, 'X': -1, '0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5}\n","    bureau_balance['STATUS'] = bureau_balance['STATUS'].map(status_mapping)\n","\n","    # Aggregate bureau_balance\n","    bureau_balance_agg = bureau_balance.groupby('SK_ID_BUREAU').agg({\n","        'MONTHS_BALANCE': ['min', 'max', 'size'],\n","        'STATUS': ['mean']\n","    }).reset_index()\n","    bureau_balance_agg.columns = ['_'.join(col).strip() for col in bureau_balance_agg.columns.values]\n","\n","    # Merge aggregated bureau_balance with bureau\n","    bureau = bureau.merge(bureau_balance_agg, how='left', left_on='SK_ID_BUREAU', right_on='SK_ID_BUREAU_')\n","\n","    # Aggregate bureau\n","    bureau_agg = bureau.groupby('SK_ID_CURR').agg({\n","        'DAYS_CREDIT': ['mean', 'max', 'min'],\n","        'CREDIT_DAY_OVERDUE': ['mean', 'max'],\n","        'AMT_CREDIT_MAX_OVERDUE': ['mean', 'max'],\n","        'CNT_CREDIT_PROLONG': ['sum'],\n","        'AMT_CREDIT_SUM': ['mean', 'sum', 'max'],\n","        'AMT_CREDIT_SUM_DEBT': ['mean', 'sum'],\n","        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n","        'AMT_CREDIT_SUM_OVERDUE': ['mean', 'sum'],\n","        'DAYS_CREDIT_UPDATE': ['mean', 'max'],\n","        'AMT_ANNUITY': ['mean', 'sum'],\n","        'MONTHS_BALANCE_min': ['mean'],\n","        'MONTHS_BALANCE_max': ['mean'],\n","        'MONTHS_BALANCE_size': ['mean'],\n","        'STATUS_mean': ['mean']\n","    }).reset_index()\n","\n","    # Flatten column names\n","    bureau_agg.columns = ['_'.join(col).strip() if col[1] else col[0] for col in bureau_agg.columns.values]\n","    return bureau_agg\n","\n","def aggregate_prev_app(prev_app):\n","    prev_app = encode_categorical(prev_app)\n","    # Only use the most significant fields to avoid noise and overfitting\n","    prev_app_agg = prev_app.groupby('SK_ID_CURR').agg({\n","        'AMT_ANNUITY': ['mean', 'max', 'sum'],\n","        'AMT_APPLICATION': ['mean', 'max', 'sum'],\n","        'AMT_CREDIT': ['mean', 'max', 'sum'],\n","        'AMT_DOWN_PAYMENT': ['mean', 'max', 'sum'],\n","        'AMT_GOODS_PRICE': ['mean', 'max', 'sum'],\n","        'HOUR_APPR_PROCESS_START': ['mean', 'max', 'min'],\n","        'RATE_DOWN_PAYMENT': ['mean', 'max', 'min'],\n","        'DAYS_DECISION': ['mean', 'max', 'min'],\n","        'CNT_PAYMENT': ['mean', 'max', 'sum']\n","    }).reset_index()\n","\n","    prev_app_agg.columns = ['_'.join(col).strip() if col[1] else col[0] for col in prev_app_agg.columns.values]\n","    return prev_app_agg\n","\n","def aggregate_pos_cash(pos_cash):\n","    pos_cash = encode_categorical(pos_cash)\n","    # Only use the most significant fields to avoid noise and overfitting\n","    pos_cash_agg = pos_cash.groupby('SK_ID_CURR').agg({\n","        'MONTHS_BALANCE': ['mean', 'max', 'min', 'size'],\n","        'SK_DPD': ['mean', 'max', 'sum'],\n","        'SK_DPD_DEF': ['mean', 'max', 'sum']\n","    }).reset_index()\n","\n","    pos_cash_agg.columns = ['_'.join(col).strip() if col[1] else col[0] for col in pos_cash_agg.columns.values]\n","    return pos_cash_agg\n","\n","def aggregate_installments(installments):\n","    installments = encode_categorical(installments)\n","    # Only use the most significant fields to avoid noise and overfitting\n","    installments_agg = installments.groupby('SK_ID_CURR').agg({\n","        'NUM_INSTALMENT_VERSION': ['nunique'],\n","        'NUM_INSTALMENT_NUMBER': ['mean', 'max', 'sum'],\n","        'DAYS_INSTALMENT': ['mean', 'max', 'min'],\n","        'DAYS_ENTRY_PAYMENT': ['mean', 'max', 'min'],\n","        'AMT_INSTALMENT': ['mean', 'max', 'sum'],\n","        'AMT_PAYMENT': ['mean', 'max', 'sum']\n","    }).reset_index()\n","\n","    installments_agg.columns = ['_'.join(col).strip() if col[1] else col[0] for col in installments_agg.columns.values]\n","    return installments_agg\n","\n","def aggregate_credit_card(credit_card):\n","    credit_card = encode_categorical(credit_card)\n","    # Only use the most significant fields to avoid noise and overfitting\n","    credit_card_agg = credit_card.groupby('SK_ID_CURR').agg({\n","        'MONTHS_BALANCE': ['mean', 'max', 'min', 'size'],\n","        'AMT_BALANCE': ['mean', 'max', 'sum'],\n","        'AMT_CREDIT_LIMIT_ACTUAL': ['mean', 'max', 'sum'],\n","        'AMT_DRAWINGS_ATM_CURRENT': ['mean', 'max', 'sum'],\n","        'AMT_DRAWINGS_CURRENT': ['mean', 'max', 'sum'],\n","        'AMT_DRAWINGS_OTHER_CURRENT': ['mean', 'max', 'sum'],\n","        'AMT_DRAWINGS_POS_CURRENT': ['mean', 'max', 'sum'],\n","        'AMT_INST_MIN_REGULARITY': ['mean', 'max', 'sum'],\n","        'AMT_PAYMENT_TOTAL_CURRENT': ['mean', 'max', 'sum'],\n","        'AMT_RECEIVABLE_PRINCIPAL': ['mean', 'max', 'sum'],\n","        'AMT_RECIVABLE': ['mean', 'max', 'sum'],\n","        'AMT_TOTAL_RECEIVABLE': ['mean', 'max', 'sum'],\n","        'CNT_DRAWINGS_ATM_CURRENT': ['mean', 'max', 'sum'],\n","        'CNT_DRAWINGS_CURRENT': ['mean', 'max', 'sum'],\n","        'CNT_DRAWINGS_OTHER_CURRENT': ['mean', 'max', 'sum'],\n","        'CNT_DRAWINGS_POS_CURRENT': ['mean', 'max', 'sum'],\n","        'CNT_INSTALMENT_MATURE_CUM': ['mean', 'max', 'sum'],\n","        'SK_DPD': ['mean', 'max', 'sum'],\n","        'SK_DPD_DEF': ['mean', 'max', 'sum']\n","    }).reset_index()\n","\n","    credit_card_agg.columns = ['_'.join(col).strip() if col[1] else col[0] for col in credit_card_agg.columns.values]\n","    return credit_card_agg"],"metadata":{"id":"cmid_howCY8T","executionInfo":{"status":"ok","timestamp":1718155082408,"user_tz":-420,"elapsed":3242,"user":{"displayName":"Nguyen Duc Quoc Anh","userId":"05926175353841331871"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### 2.2 MERGING ALL OTHER DATASETS INTO TRAIN AND TEST"],"metadata":{"id":"shgvtXnAUkoT"}},{"cell_type":"code","source":["# Aggregate and merge additional datasets\n","bureau_agg = aggregate_bureau(bureau, bureau_balance)\n","prev_app_agg = aggregate_prev_app(previous_application)\n","pos_cash_agg = aggregate_pos_cash(pos_cash_balance)\n","installments_agg = aggregate_installments(installments_payments)\n","credit_card_agg = aggregate_credit_card(credit_card_balance)\n","\n","# Merge aggregated datasets into train and test\n","train = train.merge(bureau_agg, on='SK_ID_CURR', how='left')\n","test = test.merge(bureau_agg, on='SK_ID_CURR', how='left')\n","\n","train = train.merge(prev_app_agg, on='SK_ID_CURR', how='left')\n","test = test.merge(prev_app_agg, on='SK_ID_CURR', how='left')\n","\n","train = train.merge(pos_cash_agg, on='SK_ID_CURR', how='left')\n","test = test.merge(pos_cash_agg, on='SK_ID_CURR', how='left')\n","\n","train = train.merge(installments_agg, on='SK_ID_CURR', how='left')\n","test = test.merge(installments_agg, on='SK_ID_CURR', how='left')\n","\n","train = train.merge(credit_card_agg, on='SK_ID_CURR', how='left')\n","test = test.merge(credit_card_agg, on='SK_ID_CURR', how='left')"],"metadata":{"id":"zaxB3QyI701w","executionInfo":{"status":"ok","timestamp":1718155105230,"user_tz":-420,"elapsed":22823,"user":{"displayName":"Nguyen Duc Quoc Anh","userId":"05926175353841331871"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["train.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kAFaa1RtAHL7","executionInfo":{"status":"ok","timestamp":1718155105230,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nguyen Duc Quoc Anh","userId":"05926175353841331871"}},"outputId":"2cea1663-2ab6-4811-8e97-29804e066e06"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['SK_ID_CURR', 'TARGET', 'NAME_CONTRACT_TYPE', 'CODE_GENDER',\n","       'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL',\n","       'AMT_CREDIT', 'AMT_ANNUITY',\n","       ...\n","       'CNT_DRAWINGS_POS_CURRENT_sum', 'CNT_INSTALMENT_MATURE_CUM_mean',\n","       'CNT_INSTALMENT_MATURE_CUM_max', 'CNT_INSTALMENT_MATURE_CUM_sum',\n","       'SK_DPD_mean_y', 'SK_DPD_max_y', 'SK_DPD_sum_y', 'SK_DPD_DEF_mean_y',\n","       'SK_DPD_DEF_max_y', 'SK_DPD_DEF_sum_y'],\n","      dtype='object', length=258)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":256},"id":"FkxiELeaFyiU","executionInfo":{"status":"ok","timestamp":1718155105230,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nguyen Duc Quoc Anh","userId":"05926175353841331871"}},"outputId":"cf34479b-be60-4438-ddf2-c3bde49dfcbf"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n","0      100002       1         Cash loans           M            N   \n","1      100003       0         Cash loans           F            N   \n","2      100004       0    Revolving loans           M            Y   \n","3      100006       0         Cash loans           F            N   \n","4      100007       0         Cash loans           M            N   \n","\n","  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n","0               Y             0          202500.0    406597.5      24700.5   \n","1               N             0          270000.0   1293502.5      35698.5   \n","2               Y             0           67500.0    135000.0       6750.0   \n","3               Y             0          135000.0    312682.5      29686.5   \n","4               Y             0          121500.0    513000.0      21865.5   \n","\n","   ...  CNT_DRAWINGS_POS_CURRENT_sum CNT_INSTALMENT_MATURE_CUM_mean  \\\n","0  ...                           NaN                            NaN   \n","1  ...                           NaN                            NaN   \n","2  ...                           NaN                            NaN   \n","3  ...                           0.0                            0.0   \n","4  ...                           NaN                            NaN   \n","\n","  CNT_INSTALMENT_MATURE_CUM_max CNT_INSTALMENT_MATURE_CUM_sum SK_DPD_mean_y  \\\n","0                           NaN                           NaN           NaN   \n","1                           NaN                           NaN           NaN   \n","2                           NaN                           NaN           NaN   \n","3                           0.0                           0.0           0.0   \n","4                           NaN                           NaN           NaN   \n","\n","  SK_DPD_max_y  SK_DPD_sum_y  SK_DPD_DEF_mean_y  SK_DPD_DEF_max_y  \\\n","0          NaN           NaN                NaN               NaN   \n","1          NaN           NaN                NaN               NaN   \n","2          NaN           NaN                NaN               NaN   \n","3          0.0           0.0                0.0               0.0   \n","4          NaN           NaN                NaN               NaN   \n","\n","   SK_DPD_DEF_sum_y  \n","0               NaN  \n","1               NaN  \n","2               NaN  \n","3               0.0  \n","4               NaN  \n","\n","[5 rows x 258 columns]"],"text/html":["\n","  <div id=\"df-8b235c5e-45db-40c0-98cb-69f5f03452f7\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SK_ID_CURR</th>\n","      <th>TARGET</th>\n","      <th>NAME_CONTRACT_TYPE</th>\n","      <th>CODE_GENDER</th>\n","      <th>FLAG_OWN_CAR</th>\n","      <th>FLAG_OWN_REALTY</th>\n","      <th>CNT_CHILDREN</th>\n","      <th>AMT_INCOME_TOTAL</th>\n","      <th>AMT_CREDIT</th>\n","      <th>AMT_ANNUITY</th>\n","      <th>...</th>\n","      <th>CNT_DRAWINGS_POS_CURRENT_sum</th>\n","      <th>CNT_INSTALMENT_MATURE_CUM_mean</th>\n","      <th>CNT_INSTALMENT_MATURE_CUM_max</th>\n","      <th>CNT_INSTALMENT_MATURE_CUM_sum</th>\n","      <th>SK_DPD_mean_y</th>\n","      <th>SK_DPD_max_y</th>\n","      <th>SK_DPD_sum_y</th>\n","      <th>SK_DPD_DEF_mean_y</th>\n","      <th>SK_DPD_DEF_max_y</th>\n","      <th>SK_DPD_DEF_sum_y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>100002</td>\n","      <td>1</td>\n","      <td>Cash loans</td>\n","      <td>M</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>202500.0</td>\n","      <td>406597.5</td>\n","      <td>24700.5</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>100003</td>\n","      <td>0</td>\n","      <td>Cash loans</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>0</td>\n","      <td>270000.0</td>\n","      <td>1293502.5</td>\n","      <td>35698.5</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>100004</td>\n","      <td>0</td>\n","      <td>Revolving loans</td>\n","      <td>M</td>\n","      <td>Y</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>67500.0</td>\n","      <td>135000.0</td>\n","      <td>6750.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>100006</td>\n","      <td>0</td>\n","      <td>Cash loans</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>135000.0</td>\n","      <td>312682.5</td>\n","      <td>29686.5</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>100007</td>\n","      <td>0</td>\n","      <td>Cash loans</td>\n","      <td>M</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>121500.0</td>\n","      <td>513000.0</td>\n","      <td>21865.5</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 258 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b235c5e-45db-40c0-98cb-69f5f03452f7')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8b235c5e-45db-40c0-98cb-69f5f03452f7 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8b235c5e-45db-40c0-98cb-69f5f03452f7');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-38da3397-252f-4706-96ae-03464c50346d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38da3397-252f-4706-96ae-03464c50346d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-38da3397-252f-4706-96ae-03464c50346d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train"}},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["## 3. MISSING DATA & IMPUTATION"],"metadata":{"id":"N0uJgQQaH6UO"}},{"cell_type":"markdown","source":["### 3.1 MISSING DATA"],"metadata":{"id":"rNEWRpmzICQN"}},{"cell_type":"code","source":["# Calculate total missing values in the train dataset\n","total_missing = train.isnull().sum().sum()\n","\n","# Calculate total entries in the dataset\n","total_entries = np.product(train.shape)\n","\n","# Calculate the percentage of missing data\n","missing_percentage = (total_missing / total_entries) * 100\n","\n","print(f\"Total missing data in train: {total_missing}\")\n","print(f\"Total entries in train: {total_entries}\")\n","print(f\"Percentage of missing data in train: {missing_percentage:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XYrmOBA5GHY7","executionInfo":{"status":"ok","timestamp":1718155105945,"user_tz":-420,"elapsed":718,"user":{"displayName":"Nguyen Duc Quoc Anh","userId":"05926175353841331871"}},"outputId":"c0f93618-6526-4ba1-834f-58cf41b0f202"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Total missing data in train: 25383166\n","Total entries in train: 79337838\n","Percentage of missing data in train: 31.99%\n"]}]},{"cell_type":"code","source":["# Calculate total missing values in the test dataset\n","total_missing = test.isnull().sum().sum()\n","\n","# Calculate total entries in the dataset\n","total_entries = np.product(test.shape)\n","\n","# Calculate the percentage of missing data\n","missing_percentage = (total_missing / total_entries) * 100\n","\n","print(f\"Total missing data in test: {total_missing}\")\n","print(f\"Total entries in test: {total_entries}\")\n","print(f\"Percentage of missing data in test: {missing_percentage:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M7CIjcJhIbHx","executionInfo":{"status":"ok","timestamp":1718155105945,"user_tz":-420,"elapsed":2,"user":{"displayName":"Nguyen Duc Quoc Anh","userId":"05926175353841331871"}},"outputId":"f3d2d777-bd95-495b-f876-230e62e341fc"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Total missing data in test: 3590712\n","Total entries in test: 12527208\n","Percentage of missing data in test: 28.66%\n"]}]},{"cell_type":"markdown","source":["### 3.2 IMPUTATION OF MISSING DATA\n","Given that not too much data is missing in the train and test datasets, in this notebook, we will employ simple strategies for filling missing values:\n","* Missing nummerical values will be filled with mean\n","* Missing categorical values will be filled with \"missing\"\n","\n","We will go on to experiment with K-Nearest Neighbors (KNN) Imputation later."],"metadata":{"id":"AHf_pdTfItD2"}},{"cell_type":"code","source":["def fill_missing_values(df):\n","    # Separate numerical and categorical columns\n","    num_cols = df.select_dtypes(include=[np.number]).columns\n","    cat_cols = df.select_dtypes(include=['object']).columns\n","\n","    # Fill missing values in numerical columns with mean\n","    for col in num_cols:\n","        df[col].fillna(df[col].mean(), inplace=True)\n","\n","    # Fill missing values in categorical columns with 'missing'\n","    for col in cat_cols:\n","        df[col].fillna('missing', inplace=True)\n","\n","    return df"],"metadata":{"id":"VthpqF20Ih0z","executionInfo":{"status":"ok","timestamp":1718155105945,"user_tz":-420,"elapsed":1,"user":{"displayName":"Nguyen Duc Quoc Anh","userId":"05926175353841331871"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Fill missing values in main datasets\n","train = fill_missing_values(train)\n","test = fill_missing_values(test)\n","\n","# Encode\n","train = encode_categorical(train)\n","test = encode_categorical(test)"],"metadata":{"id":"tjxU76p9K5Qc","executionInfo":{"status":"ok","timestamp":1718155108693,"user_tz":-420,"elapsed":2749,"user":{"displayName":"Nguyen Duc Quoc Anh","userId":"05926175353841331871"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Check for missing values in train dataset\n","missing_values_train = train.isnull().sum()\n","missing_values_train = missing_values_train[missing_values_train > 0]  # Filter out columns with no missing values\n","print(\"Missing values in train dataset:\")\n","print(missing_values_train)\n","\n","# Check for missing values in test dataset\n","missing_values_test = test.isnull().sum()\n","missing_values_test = missing_values_test[missing_values_test > 0]  # Filter out columns with no missing values\n","print(\"Missing values in test dataset:\")\n","print(missing_values_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1b3VEdLNK_xb","executionInfo":{"status":"ok","timestamp":1718155108693,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nguyen Duc Quoc Anh","userId":"05926175353841331871"}},"outputId":"99f49ff1-e91b-448b-9728-3b6173ba4e0d"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Missing values in train dataset:\n","Series([], dtype: int64)\n","Missing values in test dataset:\n","Series([], dtype: int64)\n"]}]},{"cell_type":"markdown","source":["# IV. MODELLING\n","\n","In this notebook, we will use a single model for the problem. One of the best choices would be LightGBM (Light Gradient Boosting Machine). LightGBM is highly efficient and capable of handling large datasets with many features like our problem in question.\n","\n","The competition uses Area Under the ROC Curve as the metric."],"metadata":{"id":"WkeVghiOQZa_"}},{"cell_type":"code","source":["import lightgbm as lgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_auc_score\n","\n","# Prepare data for LightGBM\n","X = train.drop(['TARGET', 'SK_ID_CURR'], axis=1)\n","y = train['TARGET']\n","X_test = test.drop(['SK_ID_CURR'], axis=1)\n","\n","# Split data for validation\n","X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Create LightGBM dataset\n","dtrain = lgb.Dataset(X_train, label=y_train)\n","dvalid = lgb.Dataset(X_valid, label=y_valid, reference=dtrain)\n","\n","# Set parameters\n","params = {\n","    'objective': 'binary',\n","    'boosting_type': 'gbdt',\n","    'metric': 'auc',\n","    'learning_rate': 0.01,\n","    'num_leaves': 31,\n","    'max_bin': 255,\n","    'feature_fraction': 0.9,\n","    'bagging_fraction': 0.9,\n","    'bagging_freq': 5,\n","    'early_stopping_round':100,\n","    'verbose': -1\n","}\n","\n","# Train the model\n","clf = lgb.train(\n","    params,\n","    dtrain,\n","    num_boost_round=10000,\n","    valid_sets=[dtrain, dvalid]\n",")\n","\n","# Predict\n","y_pred = clf.predict(X_valid, num_iteration=clf.best_iteration)\n","print('Validation AUC score:', roc_auc_score(y_valid, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"in922kGkMDQV","executionInfo":{"status":"ok","timestamp":1718164245180,"user_tz":-420,"elapsed":202774,"user":{"displayName":"Nguyen Duc Quoc Anh","userId":"05926175353841331871"}},"outputId":"3d83e252-9659-45f4-ffe7-a55f2a0c6e96"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation AUC score: 0.7812848211284044\n"]}]},{"cell_type":"markdown","source":["# V. HYPERPARAMETER TUNING\n","A AUC score of 0.7812 is quite encouraging. Let's see if we can further improve it by hyperparameter tuning with RandomSearchCV."],"metadata":{"id":"8TKV1H_M_B71"}},{"cell_type":"markdown","source":["## 1. HYPERPARAMETER TUNING"],"metadata":{"id":"0RoCs870ku5s"}},{"cell_type":"code","source":["# This section can be run independently from section IV\n","import lightgbm as lgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_auc_score\n","from sklearn.model_selection import RandomizedSearchCV\n","\n","# Prepare data for LightGBM\n","X = train.drop(['TARGET', 'SK_ID_CURR'], axis=1)\n","y = train['TARGET']\n","X_test = test.drop(['SK_ID_CURR'], axis=1)\n","\n","# Split data for validation\n","X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Define the parameter grid\n","param_grid = {\n","    'learning_rate': [0.01, 0.05, 0.1, 0.15],\n","    'num_leaves': [31, 50, 70, 90],\n","    'max_depth': [-1, 10, 20, 30],\n","    'min_data_in_leaf': [20, 50, 100],\n","    'feature_fraction': [0.8, 0.9, 1.0],\n","    'bagging_fraction': [0.8, 0.9, 1.0],\n","    'bagging_freq': [0, 5, 10, 15],\n","    'lambda_l1': [0, 0.1, 0.5, 1.0],\n","    'lambda_l2': [0, 0.1, 0.5, 1.0]\n","}\n","\n","# Create LightGBM dataset\n","dtrain = lgb.Dataset(X_train, label=y_train)\n","\n","# Initialize the LightGBM model\n","lgbm = lgb.LGBMClassifier(boosting_type='gbdt', objective='binary', metric='auc')\n","\n","# Perform RandomizedSearchCV\n","random_search = RandomizedSearchCV(\n","    estimator=lgbm,\n","    param_distributions=param_grid,\n","    n_iter=10,\n","    scoring='roc_auc',\n","    cv=3,\n","    verbose=1,\n","    random_state=42,\n","    n_jobs=-1\n",")\n","\n","# Fit the model\n","random_search.fit(X_train, y_train)\n","\n","# Get the best parameters\n","best_params = random_search.best_params_\n","print(\"Best parameters found by RandomizedSearchCV:\", best_params)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g6CfE7H86a7I","executionInfo":{"status":"ok","timestamp":1718161761060,"user_tz":-420,"elapsed":3467607,"user":{"displayName":"Nguyen Duc Quoc Anh","userId":"05926175353841331871"}},"outputId":"06661f6d-9b98-4abb-949b-5f27993ad701"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 10 candidates, totalling 30 fits\n","[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n","[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n","[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n","[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n","[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n","[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n","[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n","[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n","[LightGBM] [Info] Number of positive: 19876, number of negative: 226132\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.256402 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 41417\n","[LightGBM] [Info] Number of data points in the train set: 246008, number of used features: 251\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080794 -> initscore=-2.431606\n","[LightGBM] [Info] Start training from score -2.431606\n","Best parameters found by RandomizedSearchCV: {'num_leaves': 70, 'min_data_in_leaf': 50, 'max_depth': 30, 'learning_rate': 0.1, 'lambda_l2': 1.0, 'lambda_l1': 0.1, 'feature_fraction': 0.9, 'bagging_freq': 5, 'bagging_fraction': 1.0}\n"]}]},{"cell_type":"code","source":["best_params = random_search.best_params_\n","best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nzom0vsdfAyI","executionInfo":{"status":"ok","timestamp":1718162840951,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nguyen Duc Quoc Anh","userId":"05926175353841331871"}},"outputId":"e6f67647-35d3-40a5-9949-ca4289782fb9"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'num_leaves': 70,\n"," 'min_data_in_leaf': 50,\n"," 'max_depth': 30,\n"," 'learning_rate': 0.1,\n"," 'lambda_l2': 1.0,\n"," 'lambda_l1': 0.1,\n"," 'feature_fraction': 0.9,\n"," 'bagging_freq': 5,\n"," 'bagging_fraction': 1.0}"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["Best parameters found by RandomizedSearchCV: {'num_leaves': 70, 'min_data_in_leaf': 50, 'max_depth': 30, 'learning_rate': 0.1, 'lambda_l2': 1.0, 'lambda_l1': 0.1, 'feature_fraction': 0.9, 'bagging_freq': 5, 'bagging_fraction': 1.0}"],"metadata":{"id":"MbHiF5Bye2JK"}},{"cell_type":"code","source":["best_params.update({\n","    'objective': 'binary',\n","    'metric': 'auc',\n","    'early_stopping_round':100,\n","    'boosting_type': 'gbdt'\n","})\n","# Create LightGBM dataset\n","dtrain = lgb.Dataset(X_train, label=y_train)\n","dvalid = lgb.Dataset(X_valid, label=y_valid, reference=dtrain)\n","\n","# Train the model\n","clf_tuned = lgb.train(\n","    best_params,\n","    dtrain,\n","    num_boost_round=10000,\n","    valid_sets=[dtrain, dvalid]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AlpY4QSAAMkw","executionInfo":{"status":"ok","timestamp":1718163964334,"user_tz":-420,"elapsed":27340,"user":{"displayName":"Nguyen Duc Quoc Anh","userId":"05926175353841331871"}},"outputId":"bf776bfe-9ea6-43bf-ddf5-508a1faca19d"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 19876, number of negative: 226132\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.167707 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 41417\n","[LightGBM] [Info] Number of data points in the train set: 246008, number of used features: 251\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080794 -> initscore=-2.431606\n","[LightGBM] [Info] Start training from score -2.431606\n","Training until validation scores don't improve for 100 rounds\n","Early stopping, best iteration is:\n","[186]\ttraining's auc: 0.909627\tvalid_1's auc: 0.777496\n"]}]},{"cell_type":"code","source":["# Predict\n","y_pred = clf_tuned.predict(X_valid, num_iteration=clf_tuned.best_iteration)\n","print('Validation AUC score:', roc_auc_score(y_valid, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"22x7X0EOfj1v","executionInfo":{"status":"ok","timestamp":1718163976246,"user_tz":-420,"elapsed":752,"user":{"displayName":"Nguyen Duc Quoc Anh","userId":"05926175353841331871"}},"outputId":"e7bb80eb-9518-4a47-a169-584a999f4159"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation AUC score: 0.7774955749264917\n"]}]},{"cell_type":"markdown","source":["After several experiments with different options, we can see the the AUC score does not really improve. The conclusion to draw here is that for this kind of problem where there are multiple large datasets that are interconnected and sophisticated, feature aggregation and engineering should be of more significant than tuning the hyper parameters alone.\n","\n","This will be the strategy that we will take in the second notebook of this problem where we will better process the raw data and employ ensembles for better modelling."],"metadata":{"id":"O-dw_anujxlK"}},{"cell_type":"markdown","source":["## 2. PREDICTIONS ON THE TEST DATASET AND SUBMISSION FILE"],"metadata":{"id":"pc9ryxtSk4zL"}},{"cell_type":"code","source":["# Predict on the validation set\n","y_pred = clf.predict(X_valid, num_iteration=clf.best_iteration)\n","print('Validation AUC score:', roc_auc_score(y_valid, y_pred))\n","\n","# Generate predictions for the test set\n","test_pred = clf.predict(X_test, num_iteration=clf.best_iteration)\n","\n","# Create submission file\n","submission = pd.DataFrame({'SK_ID_CURR': test['SK_ID_CURR'], 'TARGET': test_pred})\n","submission.to_csv('/content/drive/MyDrive/AI/home-credit-default-risk/submission_1.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1FDGjZRYhnNV","executionInfo":{"status":"ok","timestamp":1718164479776,"user_tz":-420,"elapsed":4739,"user":{"displayName":"Nguyen Duc Quoc Anh","userId":"05926175353841331871"}},"outputId":"6d3f4b74-e55f-4aa8-9f6c-ef40a3ee712a"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation AUC score: 0.7812848211284044\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"pZ1SkCDclBDy"},"execution_count":null,"outputs":[]}]}